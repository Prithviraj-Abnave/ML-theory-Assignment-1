{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFvVJRmwh4ELIMboSUnq6p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prithviraj-Abnave/ML-theory-Assignment-1/blob/main/CancerPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b7e40e0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv('wdbc.data', header=None, names=column_names)\n",
        "\n",
        "base_features = [\n",
        "    'radius', 'texture', 'perimeter', 'area', 'smoothness',\n",
        "    'compactness', 'concavity', 'concave_points', 'symmetry', 'fractal_dimension'\n",
        "]\n",
        "\n",
        "column_names = ['ID', 'diagnosis']\n",
        "\n",
        "for feature in base_features:\n",
        "    column_names.append(f'{feature}_mean')\n",
        "\n",
        "for feature in base_features:\n",
        "    column_names.append(f'{feature}_se')\n",
        "\n",
        "for feature in base_features:\n",
        "    column_names.append(f'{feature}_worst')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m2IDjU99sQgs",
        "outputId": "1210118c-8673-4a69-cd95-810e6b356b1b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ID diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
            "0  ...         25.38          17.33           184.60      2019.0   \n",
            "1  ...         24.99          23.41           158.80      1956.0   \n",
            "2  ...         23.57          25.53           152.50      1709.0   \n",
            "3  ...         14.91          26.50            98.87       567.7   \n",
            "4  ...         22.54          16.67           152.20      1575.0   \n",
            "\n",
            "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   symmetry_worst  fractal_dimension_worst  \n",
            "0          0.4601                  0.11890  \n",
            "1          0.2750                  0.08902  \n",
            "2          0.3613                  0.08758  \n",
            "3          0.6638                  0.17300  \n",
            "4          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-x4ef2XcsUrO",
        "outputId": "4f0046e4-2772-46c5-b22c-9d75762b2339"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   ID                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave_points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave_points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave_points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 142.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JEYO3NhXsYYP",
        "outputId": "f17fbc34-2c6a-4a86-afa9-33a0702e544e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                         0\n",
            "diagnosis                  0\n",
            "radius_mean                0\n",
            "texture_mean               0\n",
            "perimeter_mean             0\n",
            "area_mean                  0\n",
            "smoothness_mean            0\n",
            "compactness_mean           0\n",
            "concavity_mean             0\n",
            "concave_points_mean        0\n",
            "symmetry_mean              0\n",
            "fractal_dimension_mean     0\n",
            "radius_se                  0\n",
            "texture_se                 0\n",
            "perimeter_se               0\n",
            "area_se                    0\n",
            "smoothness_se              0\n",
            "compactness_se             0\n",
            "concavity_se               0\n",
            "concave_points_se          0\n",
            "symmetry_se                0\n",
            "fractal_dimension_se       0\n",
            "radius_worst               0\n",
            "texture_worst              0\n",
            "perimeter_worst            0\n",
            "area_worst                 0\n",
            "smoothness_worst           0\n",
            "compactness_worst          0\n",
            "concavity_worst            0\n",
            "concave_points_worst       0\n",
            "symmetry_worst             0\n",
            "fractal_dimension_worst    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fbe6871"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['ID', 'diagnosis'], axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "y = y.map({'M': 1, 'B': 0})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9ebedc9"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "862720a7"
      },
      "source": [
        "Logistic Regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "994aa8d8",
        "outputId": "eb098a13-be94-4466-a8f3-03fcde809769"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "log_reg_model = LogisticRegression(random_state=42, solver='liblinear') # Added random_state for reproducibility and solver for older sklearn versions\n",
        "\n",
        "log_reg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_train_pred = log_reg_model.predict(X_train_scaled)\n",
        "y_test_pred = log_reg_model.predict(X_test_scaled)\n",
        "\n",
        "training_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "training_precision = precision_score(y_train, y_train_pred)\n",
        "training_recall = recall_score(y_train, y_train_pred)\n",
        "training_f1 = f1_score(y_train, y_train_pred)\n",
        "training_error = 1 - training_accuracy\n",
        "\n",
        "print(f\"Training Accuracy: {training_accuracy:.4f}\")\n",
        "print(f\"Training Precision: {training_precision:.4f}\")\n",
        "print(f\"Training Recall: {training_recall:.4f}\")\n",
        "print(f\"Training F1-score: {training_f1:.4f}\")\n",
        "print(f\"Training Error: {training_error:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_error = 1 - test_accuracy\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-score: {test_f1:.4f}\")\n",
        "print(f\"Test Error: {test_error:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*30 + \"\\n\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9874\n",
            "Training Precision: 0.9932\n",
            "Training Recall: 0.9732\n",
            "Training F1-score: 0.9831\n",
            "Training Error: 0.0126\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Test Accuracy: 0.9825\n",
            "Test Precision: 0.9688\n",
            "Test Recall: 0.9841\n",
            "Test F1-score: 0.9764\n",
            "Test Error: 0.0175\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier:"
      ],
      "metadata": {
        "id": "tgE3EXGiusIJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1789e97c",
        "outputId": "685c715f-42db-46ba-e945-7a7aea59e8ce"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_train_pred_dt = dt_model.predict(X_train_scaled)\n",
        "y_test_pred_dt = dt_model.predict(X_test_scaled)\n",
        "\n",
        "training_accuracy_dt = accuracy_score(y_train, y_train_pred_dt)\n",
        "training_precision_dt = precision_score(y_train, y_train_pred_dt)\n",
        "training_recall_dt = recall_score(y_train, y_train_pred_dt)\n",
        "training_f1_dt = f1_score(y_train, y_train_pred_dt)\n",
        "training_error_dt = 1 - training_accuracy_dt\n",
        "\n",
        "print(f\"Training Accuracy: {training_accuracy_dt:.4f}\")\n",
        "print(f\"Training Precision: {training_precision_dt:.4f}\")\n",
        "print(f\"Training Recall: {training_recall_dt:.4f}\")\n",
        "print(f\"Training F1-score: {training_f1_dt:.4f}\")\n",
        "print(f\"Training Error: {training_error_dt:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
        "\n",
        "test_accuracy_dt = accuracy_score(y_test, y_test_pred_dt)\n",
        "test_precision_dt = precision_score(y_test, y_test_pred_dt)\n",
        "test_recall_dt = recall_score(y_test, y_test_pred_dt)\n",
        "test_f1_dt = f1_score(y_test, y_test_pred_dt)\n",
        "test_error_dt = 1 - test_accuracy_dt\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy_dt:.4f}\")\n",
        "print(f\"Test Precision: {test_precision_dt:.4f}\")\n",
        "print(f\"Test Recall: {test_recall_dt:.4f}\")\n",
        "print(f\"Test F1-score: {test_f1_dt:.4f}\")\n",
        "print(f\"Test Error: {test_error_dt:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*30 + \"\\n\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Training Precision: 1.0000\n",
            "Training Recall: 1.0000\n",
            "Training F1-score: 1.0000\n",
            "Training Error: 0.0000\n",
            "\n",
            "------------------------------\n",
            "\n",
            "Test Accuracy: 0.9415\n",
            "Test Precision: 0.8955\n",
            "Test Recall: 0.9524\n",
            "Test F1-score: 0.9231\n",
            "Test Error: 0.0585\n",
            "\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dca5850"
      },
      "source": [
        "\n",
        "Logistic Regression Model\n",
        "- Training Performance:\n",
        "  - Accuracy: 0.9874\n",
        "  - Precision: 0.9932\n",
        "  - Recall: 0.9732\n",
        "  - F1-score: 0.9831\n",
        "  - Error: 0.0126\n",
        "- Test Performance:\n",
        "  - Accuracy: 0.9825\n",
        "  - Precision: 0.9688\n",
        "  - Recall: 0.9841\n",
        "  - F1-score: 0.9764\n",
        "  - Error: 0.0175\n",
        "\n",
        "Decision Tree Classifier\n",
        "- Training Performance:\n",
        "  - Accuracy: 1.0000\n",
        "  - Precision: 1.0000\n",
        "  - Recall: 1.0000\n",
        "  - F1-score: 1.0000\n",
        "  - Error: 0.0000\n",
        "- Test Performance:\n",
        "  - Accuracy: 0.9415\n",
        "  - Precision: 0.8955\n",
        "  - Recall: 0.9524\n",
        "  - F1-score: 0.9231\n",
        "  - Error: 0.0585\n",
        "\n",
        "Analysis:\n",
        "- Logistic Regression:\n",
        "The model has good accuracy and precision scores in both training and testing dataset. ~1% error in the calculation. Hence no problem of overfitting or underfitting.\n",
        "\n",
        "- Decision Tree:\n",
        "The model has good scores in training dataset but drastic performance dip in testing dataset. This is due to overfitting of features in decision tree mode.\n",
        "\n",
        "- Relavant issues in ML:\n",
        "\n",
        "1. Scaling:\n",
        "The issue occurs when the skewness of the dataset is vast, so we scale down the values for the ease of reading the data\n",
        "\n",
        "2.  High Correlation:\n",
        "Due to high correlation of data, the logistic regression model fails, but decisioin tree model is able to perform reasonably well under such conditions but it also may suffer from this issue.\n"
      ]
    }
  ]
}